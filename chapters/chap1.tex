\chapter{Euclidean Spaces}
\section{Smooth Functions on a Euclidean Space}
\begin{problem}
\end{problem}

\begin{proof}
	$$g(x) = \int_{0}^{x} t^{1/3}dt = \frac{3}{4}x^4/3$$
	$$g'(x) = x^{1/3}$$
	So, as seen before, $g'$ is $C^0$ but not $C^1$. As such, $g$ is $C^1$, but not $C^2$. And
	$h = \int_{0}^{x} g(t) dt$, which has $h' = g$, is $C^2$ but not $C^3$.
\end{proof}

\begin{problem}
\end{problem}

\begin{enumerate}[label=(\alph*)]
	\item
	      \begin{proof}
		      Base case: $k = 0$, it is obviously true, with $p_{0} = 1$. Suppose it's true for $k > 1$. Then
		      $$f^{(k)}(x) = p_{2k}(1/x)e^{-1/x} $$

		      \begin{align*}
			      f^{(k+1)}(x) & = (p_{2k}(1/x))' \cdot (e^{-1/x}) + (p_{2k}(1/x))\cdot(e^{-1/x})'                     \\
			                   & = (p_{2k})'(1/x)\frac{1}{x^2}\cdot(e^{-1/x}) + p_{2k}(1/x)\cdot e^{-1/x}\frac{1}{x^2} \\
			                   & =  e^{-1/x} \cdot \frac{(p_{2k})'(1/x) + p_{2k}(1/x)}{x^2}                            \\
		      \end{align*}
		      Now, $(p_{2k})'(1/x)/x^2$ is a polynomial on $(1/x)$ of degree $2k + 1$ and $p_{2k}(1/x)/x^2$ is of degree
		      $2k + 2$, so $(p_{2k})'(1/x)/x^2 + p_{2k}(1/x)/x^2$ is a polynomial on $(1/x)$ of degree $2k + 2$, proving the hypothesis.
	      \end{proof}
	\item \begin{proof}
		      These formula are certainly valid for any $x \neq 0$. For $x \to 0$, it suffices to notice that $e^{-1/x} \lll p_{2k}(1/x)$ for any $k$.
		      So $f^{k}$ is defined for all $\R$ and, (taking the limit) is $0$ at $0$ for any $k$.
	      \end{proof}
\end{enumerate}

\begin{problem}
\end{problem}

\begin{enumerate}[label=(\alph*)]
	\item \begin{proof}
		      $\tan$ is $C^\infty$ on $(-\pi/2,\pi/2)$ as, taking derivatives, on the denominators only $\cos$ appears and they never 0
		      on this interval. Its inverse, $\arctan$ has derivative $\frac{1}{1+x^2}$ which
		      also is $C^\infty$.
	      \end{proof}
	\item \begin{proof}
		      Consider
		      $$h(x) = \frac{x - (b+a)/2}{(b-a)/2}$$
	      \end{proof}
	\item \begin{proof}
		      Consider $h(x) = \exp(x) + a$ and $g(x) = b - \exp(x)$, then clearly $h$ and $g$ are diffeomorphisms, and we may compose
		      the inverses to find that by the diffeomorphism $g\circ h^{-1}$, the intervals are diffeomorphic.
	      \end{proof}
\end{enumerate}

\begin{problem}
\end{problem}
\begin{proof}
	Consider the smooth inverse
	$$g : \R^n \to \bigg(-\frac{\pi}{2}, \frac{\pi}{2}\bigg)^n,\quad g(x_1, \dots, x_n) = (\arctan(x_1), \dots, \arctan(x_n))$$
\end{proof}

\begin{problem}
\end{problem}
\begin{enumerate}[label=(\alph*)]
	\item \begin{proof}
		      We parametrize the line between $(0,0,1)$ and $(a,b,c)$ by $t$ and solve for when $z = 0$.
		      $$l(t) = (0,0,1) + t \cdot ((a,b,c) - (0,0,1)) = (ta, tb, 1 + t(c-1))$$
		      $$l_3(t) = 0 \iff 1 + t(c-1) = 0 \iff t = \frac{1}{1-c}$$
		      yielding precisely
		      $$g(a,b,c) = \bigg( \frac{a}{1-c}, \frac{b}{1-c} \bigg)$$
		      as $(a,b,c) \in S$, we know that $c = 1 - \sqrt{1 - a^2 - b^2}$.

		      For the inverse, we procede the same way, solving the line equation for when $|l(t) - (0,0,1)| = 1$.
		      This time it is given by:
		      $$l(t) = (0,0,1) + t\cdot ((x,y,0) - (0,0,1))$$
		      So, for $|l(t) - (0,0,1)| = 1$ to happen, we must have:
		      $$t^2x^2 +t^2y^2 +t^2 = 1 \iff t^2(x^2 + y^2 + 1) = 1$$
		      yielding $t = \pm 1/\sqrt{x^2 + y^2  +1}$, as we know our solution is in the lower hemisphere, we have
		      $t = 1/\sqrt{x^2 + y^2  +1}$. Substituting back on the line equation we find
		      $$(a,b,c) = \bigg(\frac{x}{\sqrt{x^2 + y^2 + 1}}, \frac{y}{\sqrt{x^2 + y^2 + 1}}, 1 - \frac{1}{\sqrt{x^2 + y^2 + 1}}\bigg)$$
	      \end{proof}
	\item \begin{proof}
		      $h^{-1} = f^{-1} \circ g^{-1}$, $g^{-1}$ was found in the previous item, and $f^{-1}$ is simply the projection
		      to the $xy$ plane. So
		      $$h^{-1}(u,v) = \bigg(\frac{u}{\sqrt{1 + u^2 + v^2}}, \frac{v}{\sqrt{1 + u^2 + v^2}} \bigg)$$
		      which is $C^\infty$. $h$ is a diffeomorphism.
	      \end{proof}

	\item \begin{proof}
		      This is the most interesting item, but we do exactly the same thing looking at the $S^n$ dimensional sphere in $R^{n+1}$.
		      Consider the stereographic projection $g: S \to \R^n$ from $(0,0,1)$ given by:
		      $$g(x_1, x_2, \dots, x_n, x_{n+1}) = \bigg(\frac{x_1}{1 - c}, \dots, \frac{x_{n}}{1-c}, 1 - \frac{1}{1 - c}\bigg)$$
		      where $c = 1 - \bigg(\sum_{1}^{n} (x_i)^2\bigg)^{1/2}$
		      Then, following the same construction as before, we find $h$ and $h^{-1}$ where:
		      $$h(x_1,x_2 \dots, x_n) = \bigg(\frac{x_i}{1 - c} \bigg)_{i=1}^{n}$$
		      where the expression on the right is a vector. Similarly, $h^{-1}$ is defined as:
		      $$h^{-1}(x_1,x_2 \dots, x_n) = \Bigg(\frac{x_i}{\sqrt{1 + (x_1)^2 \dots + (x_n)^2}} \Bigg)_{i=1}^{n}$$
	      \end{proof}
\end{enumerate}

\begin{problem}
\end{problem}

\begin{proof}
	We apply Taylor twice. As before, consider the function on the line $f(tx,ty))$. By the chain rule
	$$D_t f(tx,ty) = \partial_x f(tx,ty)x + \partial_y f(tx,ty)y$$
	So, integrating, we find
	$$f(x,y) - f(0,0) = D_t f(tx,ty) \bigg ]_{0}^{1} = x \int_{0}^{1} \partial_x f(tx,ty) dt + y \int_{0}^{1} \partial_y f(tx,ty) dt$$
	$$f(x,y)  = f(0,0) +  x \int_{0}^{1} \partial_x f(tx,ty) dt + y \int_{0}^{1} \partial_y f(tx,ty) dt$$
	Now we do the same for $\partial_x f(tx,ty)$ and $\partial_y f(tx,ty)$, we find:
	$$\partial_x f(x,y)  = \partial_x f(0,0) +  x \int_{0}^{1} \partial_{xx} f(tx,ty) dt + y \int_{0}^{1} \partial_{xy} f(tx,ty) dt$$
	$$\partial_y f(x,y)  = \partial_{y} f(0,0) +  x \int_{0}^{1} \partial_{yx} f(tx,ty) dt + y \int_{0}^{1} \partial_{yy} f(tx,ty) dt$$
	Substituting in the $f(x,y)$ expansion:
	\begin{align*}
		f(x,y)  = f(0,0) + & x \int_{0}^{1}\Bigg( \partial_x f(0,0) +  x \int_{0}^{1} \partial_{xx} f(stx,sty) ds + y \int_{0}^{1} \partial_{xy} f(stx,sty) ds \Bigg) dt \\
		+                  & y \int_{0}^{1}\Bigg( \partial_y f(0,0) +  x \int_{0}^{1} \partial_{yx} f(stx,sty) ds + y \int_{0}^{1} \partial_{yy} f(stx,sty) ds \Bigg) dt \\
		= f(0,0) +         & x \partial_x f(0,0) + y \partial_y f(0,0) + x^2 g_{11}(x,y) + xy g_{12}(x,y) + y^2 g_{22}(x,y)                                              \\
	\end{align*}
\end{proof}

\begin{problem}
\end{problem}

\begin{proof}
	$g(t,u)$ is 0 at $t = 0$. And, by expanding $f$, we find, for $t \neq 0$:
	\begin{equation*}
		g(t,u) = \frac{1}{t} \bigg( f(0,0)  + \partial_x f(0,0) t + \partial_y f(0,0) tu  +
		t^2 g_{11}(t,tu) + t^2u g_{12}(t,tu) + t^2u^2 g_{22}(t,tu) \bigg)
	\end{equation*}
	Noticing $f(0,0) = \partial_x f(0,0) = \partial_y f(0,0) = 0$ we get:
	$$g(t,u) = t g_{11}(t,tu) + tu g_{12}(tu) + tu^2 g_{22}(t,tu)$$
	Because $g(0,u) = 0$, this formula is valid for $t = 0$ as well, and this expression is $C^\infty$.
\end{proof}

\begin{problem}
$f^{-1} = x^{1/3}$ which is not differentiable at $0$. In complex analysis, as a consequence of Rouche's theorem,
if $f'(z) = 0$, then $f(z + s) = f''(z)s^2 + \dots$, and it can be shown that for sufficiently small $s$, we have at least two solutions.

\end{problem}

\section{Tangent Vectors in Rn as Derivations}

\begin{problem}
\end{problem}
\begin{proof}
	$$ X = x\partial_x + y\partial_y$$
	$$ f(x,y,z) =  x^2 + y^2 + z^2$$
	Then, computing $Xf$ is as simple as applying $X$ to $f$ at every point:
	$$Xf = x\partial_x f + y\partial_y f = 2x^2 + 2y^2$$
\end{proof}

\begin{problem}
\end{problem}

\begin{proof}
	We define all such operations point-wise on $C_{p}^{\infty}$. For $f,g \in C_{p}^{\infty}$ and $\lambda \in \R$,
	for any $x \in U$ :
	\begin{align*}
		(f + g) (x)     & = f(x) + g(x) = g(x) + f(x) =  (g + f)(x)             \\
		(f \cdot g) (x) & = f(x) \cdot g(x) = g(x) \cdot f(x) =  (g \cdot f)(x) \\
		(\lambda f) (x) & = \lambda \cdot f(x)
	\end{align*}
	Such operations are closed in $C_{p}^{\infty}$ as differentiability is a local property closed under these
	operations.
\end{proof}

\begin{problem}
\end{problem}


\begin{enumerate}[label=(\alph*)]
	\item \begin{proof}
		      Let $D, D'$ be derivation at $p$. Then both $D,D'$ are linear maps of the form $C_p^{\infty} \to \R$, that
		      satisfy the Leibniz rule.
		      $$(D + D')(\lambda f + g) = D(\lambda f + g) + D'(\lambda f + g) = \lambda (D + D')f + (D + D')g$$
		      So $D + D'$ is linear. We also have:
		      $$(D + D')(fg) = D(fg) + D'(fg) = (Df)g + f(Dg) + (D'f)g + f(D'g) = (D + D')(f)g + f(D + D')(g)$$
		      As we wanted to show.
	      \end{proof}
	\item \begin{proof}
		      Certainly is a linear map and the $c$ pops inside the Leibniz rule
		      $$cD(fg) = c((Df)g + f(Dg)) = (cDf)g + f(cDg)$$
	      \end{proof}
\end{enumerate}

\begin{problem}
\end{problem}
\begin{proof}
	Let $D_1,D_2: A \to A$, then $D_1 \circ D_2 : A \to A$. And:
	$$D_1 \circ D_2 (ab) = D_1(a(D_2b)) + D_1((D_2a)b) = (D_1a)(D_2b) + a(D_1D_2b) + (D_1D_2a)b + (D_2a)(D_1b)$$
	which certainly isn't necessairly equal to:
	$$a(D_1(D_2b)) + (D_1(D_2a))b$$

	Now let's consider $D_1 \circ D_2 - D_2 \circ D_1$, which is clearly a linear map.
	\begin{align*}
		(D_1 \circ D_2 - D_2 \circ D_1)(ab) & = (D_1a)(D_2b) + a(D_1D_2b) + (D_1D_2a)b + (D_2a)(D_1b) \\
		                                    & - (D_2a)(D_1b) - a(D_2D_1b) - (D_2D_1a)b - (D_1a)(D_2b) \\
		                                    & = a[D_1D_2 - D_2D_1](b) + [D_1D_2 - D_2D_1](a)b
	\end{align*}
	As we wanted to show.
\end{proof}
